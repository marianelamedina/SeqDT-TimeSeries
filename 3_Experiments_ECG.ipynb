{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from aeon.datasets import load_classification\n",
    "import numpy as np\n",
    "from SeqDT import *\n",
    "from Representation import *\n",
    "from ModelEvaluation import *\n",
    "from Discretization import *\n",
    "from TimeSeriesAnalysis import *\n",
    "from aeon.datasets.dataset_collections import get_available_tsc_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patiens = [4, 6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset AEON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "available_datasets = get_available_tsc_datasets()\n",
    "\n",
    "ecg_related = [d for d in available_datasets if 'ECG' in d or 'ecg' in d.lower()]\n",
    "\n",
    "print(\"Dataset ECG available:\")\n",
    "for dataset in ecg_related:\n",
    "    print(f\"  - {dataset}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset ECG 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = load_classification(\"ECG200\", split=\"train\")\n",
    "X_test, y_test = load_classification(\"ECG200\", split=\"test\")\n",
    "\n",
    "print(f\"Training set: {X_train.shape}\")\n",
    "print(f\"Classes: {np.unique(y_train)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ECG200 = TSAnalysis(X_train, y_train, X_test, y_test, bins = 5, method= 'Classic', patients_to_viz= patiens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(ECG200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ECG200_RLR = TSAnalysis(X_train=X_train, y_train=y_train, X_test=X_test, y_test=y_test, bins = 5, method= 'RLR', patients_to_viz= patiens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ECG datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Summary = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in ecg_related:\n",
    "    X_train, y_train = load_classification(dataset, split=\"train\")\n",
    "    X_test, y_test = load_classification(dataset, split=\"test\")\n",
    "\n",
    "    print(f'\\n\\nDATASET: {dataset}')\n",
    "    print(f\"Training set: {X_train.shape}\")\n",
    "    print(f\"Classes: {np.unique(y_train)}\")\n",
    "    \n",
    "    result = TSAnalysis(X_train=X_train, y_train=y_train, X_test=X_test, y_test=y_test, bins = 5, method= 'Classic', dataset_name= dataset)\n",
    "    \n",
    "    if Summary.empty:\n",
    "        Summary = pd.DataFrame([result])\n",
    "    else:\n",
    "        Summary = pd.concat([Summary, pd.DataFrame([result])], ignore_index=True)\n",
    "        \n",
    "        \n",
    "    result = TSAnalysis(X_train=X_train, y_train=y_train, X_test=X_test, y_test=y_test, bins = 5, method= 'RLR', dataset_name= dataset)\n",
    "    \n",
    "    Summary = pd.concat([Summary, pd.DataFrame([result])], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_conservative = {\n",
    "    'g': 1,\n",
    "    'maxL': 2,\n",
    "    'pru': True,\n",
    "    'epsilon': 0.2,\n",
    "    'minS': 0.01,\n",
    "    'minN': 5,\n",
    "    'maxD': 3,\n",
    "    'visualize': False,\n",
    "    'show_statistics': False\n",
    "}\n",
    "\n",
    "params_standard = {\n",
    "    'g': 1,\n",
    "    'maxL': 3,\n",
    "    'pru': True,\n",
    "    'epsilon': 0.15,\n",
    "    'minS': 0,\n",
    "    'minN': 2,\n",
    "    'maxD': 0,\n",
    "    'visualize': False,\n",
    "    'show_statistics': False\n",
    "}\n",
    "\n",
    "params_aggressive = {\n",
    "    'g': 1,\n",
    "    'maxL': 4,\n",
    "    'pru': True,\n",
    "    'epsilon': 0.1,\n",
    "    'minS': 0,\n",
    "    'minN': 1,\n",
    "    'maxD': 0,\n",
    "    'visualize': False,\n",
    "    'show_statistics': False\n",
    "}\n",
    "\n",
    "params_high_gap = {\n",
    "    'g': 2,\n",
    "    'maxL': 3,\n",
    "    'pru': True,\n",
    "    'epsilon': 0.15,\n",
    "    'minS': 0,\n",
    "    'minN': 2,\n",
    "    'maxD': 0,\n",
    "    'visualize': False,\n",
    "    'show_statistics': False\n",
    "}\n",
    "\n",
    "params_no_pruning = {\n",
    "    'g': 1,\n",
    "    'maxL': 3,\n",
    "    'pru': False,\n",
    "    'epsilon': 0.15,\n",
    "    'minS': 0,\n",
    "    'minN': 2,\n",
    "    'maxD': 0,\n",
    "    'visualize': False,\n",
    "    'show_statistics': False\n",
    "}\n",
    "\n",
    "params_shallow = {\n",
    "    'g': 1,\n",
    "    'maxL': 3,\n",
    "    'pru': True,\n",
    "    'epsilon': 0.15,\n",
    "    'minS': 0,\n",
    "    'minN': 2,\n",
    "    'maxD': 2,\n",
    "    'visualize': False,\n",
    "    'show_statistics': False\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "parameter_configs = {\n",
    "    'Conservative': params_conservative,\n",
    "    'Standard': params_standard,\n",
    "    'Aggressive': params_aggressive,\n",
    "    'HighGap': params_high_gap,\n",
    "    'NoPruning': params_no_pruning,\n",
    "    'Shallow': params_shallow\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins_configs = [3, 5, 7, 9]\n",
    "\n",
    "methods = ['Classic', 'RLR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Summary = pd.DataFrame()\n",
    "All_Results = pd.DataFrame()  # Salva tutti i risultati per confronto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in ecg_related:\n",
    "    try:\n",
    "        X_train, y_train = load_classification(dataset, split=\"train\")\n",
    "        X_test, y_test = load_classification(dataset, split=\"test\")\n",
    "\n",
    "        print(f'\\n{\"=\"*80}')\n",
    "        print(f'DATASET: {dataset}')\n",
    "        print(f\"Training set: {X_train.shape}\")\n",
    "        print(f\"Classes: {np.unique(y_train)}\")\n",
    "        print(f'{\"=\"*80}\\n')\n",
    "        \n",
    "        best_accuracy_for_dataset = 0\n",
    "        best_result_for_dataset = None\n",
    "        \n",
    "        \n",
    "        for bins in bins_configs:\n",
    "            for param_name, params in parameter_configs.items():\n",
    "                \n",
    "                for method in methods:\n",
    "                    try:\n",
    "                        print(f\"Testing: bins={bins}, params={param_name}, method={method}\")\n",
    "                        \n",
    "                        result = TSAnalysis(X_train=X_train, y_train=y_train, X_test=X_test, y_test=y_test,\n",
    "                                            bins=bins, method=method, dataset_name=dataset,SeqDT_parameters=params,\n",
    "                                            visualize_plots= False)\n",
    "                        \n",
    "                        result['Param_Config'] = param_name\n",
    "                        \n",
    "                        All_Results = pd.concat([All_Results, pd.DataFrame([result])], ignore_index=True)\n",
    "                        \n",
    "                        if result['Accuracy'] > best_accuracy_for_dataset:\n",
    "                            best_accuracy_for_dataset = result['Accuracy']\n",
    "                            best_result_for_dataset = result.copy()\n",
    "                        \n",
    "                    except Exception as e:\n",
    "                        print(f\"Error: {e}\")\n",
    "                \n",
    "        \n",
    "        \n",
    "        if best_result_for_dataset is not None:\n",
    "            print(f\"\\nBest result for {dataset}: Accuracy={best_accuracy_for_dataset:.4f}\")\n",
    "            Summary = pd.concat([Summary, pd.DataFrame([best_result_for_dataset])], ignore_index=True)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nCould not process dataset {dataset}: {e}\")\n",
    "        continue\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(f'\\n{\"=\"*80}')\n",
    "print(\"BEST RESULTS SUMMARY\")\n",
    "print(f'{\"=\"*80}\\n')\n",
    "\n",
    "display_cols = ['Dataset', 'Bins', 'Method', 'Param_Config', 'Accuracy', 'G-mean', 'Tree_Depth', 'Training_Time']\n",
    "print(Summary[display_cols].to_string(index=False))\n",
    "print(Summary)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
